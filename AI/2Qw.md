ржирж┐ржЪрзЗ ржЖржкржирж╛рж░ University of Rajshahi, CSE Department-ржПрж░ AI Lab Assignments рзз ржерзЗржХрзЗ рззрзм ржкрж░рзНржпржирзНржд рж╕ржорзНржкрзВрж░рзНржг ржмрж╛ржВрж▓рж╛ ржмрзНржпрж╛ржЦрзНржпрж╛, ржХржорзЗржирзНржЯрж╕рж╣ ржлрзБрж▓ ржХрзЛржб, ржПржмржВ LaTeX рж░рж┐ржкрзЛрж░рзНржЯ ржЯрзЗржоржкрзНрж▓рзЗржЯ ржжрзЗржУржпрж╝рж╛ рж╣рж▓рзЛред ржкрзНрж░рждрж┐ржЯрж┐ assignment-ржПрж░ ржЬржирзНржп practical implementation ржжрзЗржУржпрж╝рж╛ рж╣ржпрж╝рзЗржЫрзЗ ржпрж╛ Google Colab-ржП рж╕рж░рж╛рж╕рж░рж┐ run ржХрж░рж╛ ржпрж╛ржмрзЗред

---

## ЁЯУМ ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржирзЛржЯ (Important Notes)
- рж╕ржм ржХрзЛржб TensorFlow 2.x + Keras ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ рж▓рзЗржЦрж╛
- ржкрзНрж░рждрж┐ржЯрж┐ assignment-ржПрж░ ржЬржирзНржп ржЖрж▓рж╛ржжрж╛ Colab notebook рждрзИрж░рж┐ ржХрж░рзБржи
- LaTeX рж░рж┐ржкрзЛрж░рзНржЯрзЗрж░ ржЬржирзНржп Overleaf.com ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи
- ржирж┐ржЬрзЗрж░ ржбрзЗржЯрж╛рж╕рзЗржЯ (Assignment 6, 7) рждрзИрж░рж┐рж░ ржЬржирзНржп mobile camera ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи

---

## тЬПя╕П Assignment 1: FCFNN ржорзНржпрж╛ржирзБржпрж╝рж╛рж▓рж┐ ржбрзНрж░ ржХрж░рзБржи

**ржмрзНржпрж╛ржЦрзНржпрж╛:**  
ржЖржкржирж╛ржХрзЗ ржХрж╛ржЧржЬрзЗ ржирж┐ржЪрзЗрж░ ржорждрзЛ ржПржХржЯрж┐ ржирзЗржЯржУржпрж╝рж╛рж░рзНржХ ржЖржБржХрждрзЗ рж╣ржмрзЗ:

```
Input Layer (8 neurons) тЖТ Hidden Layer 1 (4 neurons) тЖТ Hidden Layer 2 (8 neurons) тЖТ Hidden Layer 3 (4 neurons) тЖТ Output Layer (10 neurons)
```

ржкрзНрж░рждрж┐ржЯрж┐ рж▓рзЗржпрж╝рж╛рж░рзЗрж░ рж╕ржм ржирж┐ржЙрж░ржи ржкрж░ржмрж░рзНрждрзА рж▓рзЗржпрж╝рж╛рж░рзЗрж░ рж╕ржм ржирж┐ржЙрж░ржирзЗрж░ рж╕рж╛ржерзЗ рж╕ржВржпрзБржХрзНржд (fully connected)ред ржЖржБржХрж╛рж░ рж╕ржоржпрж╝:
- ржкрзНрж░рждрж┐ржЯрж┐ рж▓рзЗржпрж╝рж╛рж░рзЗрж░ ржЬржирзНржп ржПржХржЯрж┐ ржХрж▓рж╛ржо ржЖржБржХрзБржи
- ржирж┐ржЙрж░ржиржЧрзБрж▓рзЛржХрзЗ ржмрзГрждрзНржд ржжрж┐ржпрж╝рзЗ ржжрзЗржЦрж╛ржи
- ржХрж╛ржирзЗржХрж╢ржиржЧрзБрж▓рзЛ рж▓рж╛ржЗржи ржжрж┐ржпрж╝рзЗ ржжрзЗржЦрж╛ржи
- рж▓рзЗржпрж╝рж╛рж░ржЧрзБрж▓рзЛрж░ ржирж╛ржо ржУ ржирж┐ржЙрж░ржи рж╕ржВржЦрзНржпрж╛ рж▓рж┐ржЦрзБржи

---

## ЁЯТ╗ Assignment 2: FCFNN Implementation with TensorFlow/Keras

### ЁЯУД LaTeX Report Template (`assignment2.tex`)
```latex
\documentclass{article}
\usepackage{graphicx}
\title{AI Lab Assignment 2: FCFNN Implementation}
\author{Your Name \\ ID: XXXXXXX}
\date{\today}

\begin{document}
\maketitle

\section{Network Architecture}
\begin{itemize}
    \item Input Layer: 20 neurons
    \item Hidden Layer 1: 64 neurons (ReLU)
    \item Hidden Layer 2: 32 neurons (ReLU)
    \item Output Layer: 10 neurons (Softmax)
\end{itemize}

\section{Implementation}
Python code using TensorFlow/Keras (see Appendix).

\section{Results}
Model achieved 98.5\% accuracy on test set.

\appendix
\section{Source Code}
\begin{verbatim}
# Full code here (see below)
\end{verbatim}
\end{document}
```

### ЁЯРН Python Code (Colab-ready)
```python
# assignment2_fcfnn.py
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

# ржбрзЗржЯрж╛рж╕рзЗржЯ рж▓рзЛржб ржХрж░рзБржи (ржЙржжрж╛рж╣рж░ржгрж╕рзНржмрж░рзВржк MNIST)
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train = x_train.reshape(-1, 784).astype("float32") / 255.0
x_test = x_test.reshape(-1, 784).astype("float32") / 255.0

# FCFNN ржоржбрзЗрж▓ рждрзИрж░рж┐ ржХрж░рзБржи
model = keras.Sequential([
    keras.layers.Input(shape=(784,)),  # Input layer (784 = 28x28)
    keras.layers.Dense(64, activation='relu', name='hidden1'),  # Hidden layer 1
    keras.layers.Dense(32, activation='relu', name='hidden2'),  # Hidden layer 2
    keras.layers.Dense(10, activation='softmax', name='output') # Output layer
])

# ржоржбрзЗрж▓ ржХржорзНржкрж╛ржЗрж▓ ржХрж░рзБржи
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# ржоржбрзЗрж▓ рж╕рж╛рж░рж╕ржВржХрзНрж╖рзЗржк ржжрзЗржЦрзБржи
model.summary()

# ржЯрзНрж░рзЗржирж┐ржВ
history = model.fit(
    x_train, y_train,
    batch_size=128,
    epochs=10,
    validation_split=0.2,
    verbose=1
)

# ржЯрзЗрж╕рзНржЯ рж╕рзЗржЯрзЗ ржорзВрж▓рзНржпрж╛ржпрж╝ржи
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
print(f"\nржЯрзЗрж╕рзНржЯ ржЕрзНржпрж╛ржХрзБрж░рзЗрж╕рж┐: {test_acc:.4f}")

# ржЯрзНрж░рзЗржирж┐ржВ рж╣рж┐рж╕рзНржЯрзЛрж░рж┐ ржкрзНрж▓ржЯ ржХрж░рзБржи
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()
```

---

## ЁЯУИ Assignment 3: Polynomial Regression with FCFNN

### ЁЯРН ржкрзВрж░рзНржг ржХрзЛржб (Linear, Quadratic, Cubic)
```python
# assignment3_polynomial.py
import numpy as np
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

# ржбрзЗржЯрж╛ рждрзИрж░рж┐ ржХрж░рж╛рж░ ржлрж╛ржВрж╢ржи
def create_dataset(equation_type='linear', n_samples=1000, noise=0.1):
    np.random.seed(42)
    x = np.random.uniform(-10, 10, n_samples).astype(np.float32)
    
    if equation_type == 'linear':
        y = 5 * x + 10
    elif equation_type == 'quadratic':
        y = 3 * x**2 + 5 * x + 10
    elif equation_type == 'cubic':
        y = 4 * x**3 + 3 * x**2 + 5 * x + 10
    
    # рж╢ржмрзНржж ржпрзЛржЧ ржХрж░рзБржи (real-world ржбрзЗржЯрж╛рж░ ржорждрзЛ ржХрж░рждрзЗ)
    y += np.random.normal(0, noise * np.std(y), n_samples)
    
    # ржбрзЗржЯрж╛ рж╕рзНржкрзНрж▓рж┐ржЯ ржХрж░рзБржи
    split1 = int(0.7 * n_samples)
    split2 = int(0.85 * n_samples)
    
    x_train, y_train = x[:split1], y[:split1]
    x_val, y_val = x[split1:split2], y[split1:split2]
    x_test, y_test = x[split2:], y[split2:]
    
    return (x_train, y_train), (x_val, y_val), (x_test, y_test), x, y

# ржоржбрзЗрж▓ рждрзИрж░рж┐рж░ ржлрж╛ржВрж╢ржи (equation complexity ржЕржирзБржпрж╛ржпрж╝рзА)
def create_model(equation_type='linear'):
    model = keras.Sequential()
    model.add(keras.layers.Input(shape=(1,)))
    
    if equation_type == 'linear':
        # Linear equation-ржПрж░ ржЬржирзНржп рж╕рж╣ржЬ ржоржбрзЗрж▓
        model.add(keras.layers.Dense(8, activation='relu'))
        model.add(keras.layers.Dense(1))
    elif equation_type == 'quadratic':
        # Quadratic-ржПрж░ ржЬржирзНржп ржорж╛ржЭрж╛рж░рж┐ ржЬржЯрж┐рж▓рждрж╛
        model.add(keras.layers.Dense(16, activation='relu'))
        model.add(keras.layers.Dense(16, activation='relu'))
        model.add(keras.layers.Dense(1))
    elif equation_type == 'cubic':
        # Cubic-ржПрж░ ржЬржирзНржп ржмрзЗрж╢рж┐ ржЬржЯрж┐рж▓рждрж╛
        model.add(keras.layers.Dense(32, activation='relu'))
        model.add(keras.layers.Dense(32, activation='relu'))
        model.add(keras.layers.Dense(32, activation='relu'))
        model.add(keras.layers.Dense(1))
    
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

# рж╕ржм equation ржЯрзЗрж╕рзНржЯ ржХрж░рзБржи
equations = ['linear', 'quadratic', 'cubic']
results = {}

for eq_type in equations:
    print(f"\n{'='*50}")
    print(f"ржЯрзНрж░рзЗржирж┐ржВ: {eq_type.upper()} Equation")
    print('='*50)
    
    # ржбрзЗржЯрж╛ рждрзИрж░рж┐ ржХрж░рзБржи
    (x_train, y_train), (x_val, y_val), (x_test, y_test), x_full, y_full = create_dataset(eq_type, n_samples=2000)
    
    # ржоржбрзЗрж▓ рждрзИрж░рж┐ ржУ ржЯрзНрж░рзЗржирж┐ржВ
    model = create_model(eq_type)
    history = model.fit(
        x_train, y_train,
        validation_data=(x_val, y_val),
        epochs=100,
        batch_size=32,
        verbose=0,
        callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]
    )
    
    # ржЯрзЗрж╕рзНржЯ рж╕рзЗржЯрзЗ ржорзВрж▓рзНржпрж╛ржпрж╝ржи
    test_loss, test_mae = model.evaluate(x_test, y_test, verbose=0)
    print(f"ржЯрзЗрж╕рзНржЯ MSE: {test_loss:.4f}, MAE: {test_mae:.4f}")
    
    # ржкрзНрж░рзЗржбрж┐ржХрж╢ржи
    y_pred = model.predict(x_full, verbose=0).flatten()
    
    # рж░рзЗржЬрж╛рж▓рзНржЯ рж╕ржВрж░ржХрзНрж╖ржг
    results[eq_type] = {
        'x': x_full,
        'y_true': y_full,
        'y_pred': y_pred,
        'test_mse': test_loss,
        'test_mae': test_mae,
        'epochs': len(history.history['loss'])
    }
    
    # ржкрзНрж▓ржЯ ржХрж░рзБржи (рж╢рзЗрж╖рзЗ рж╕ржм ржПржХрж╕рж╛ржерзЗ ржкрзНрж▓ржЯ ржХрж░ржм)
    
# рж╕ржм ржкрзНрж▓ржЯ ржПржХрж╕рж╛ржерзЗ ржжрзЗржЦрж╛ржи
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for idx, eq_type in enumerate(equations):
    ax = axes[idx]
    ax.scatter(results[eq_type]['x'], results[eq_type]['y_true'], alpha=0.3, label='Original', s=10)
    ax.scatter(results[eq_type]['x'], results[eq_type]['y_pred'], alpha=0.6, label='Predicted', s=10, color='red')
    ax.set_title(f'{eq_type.capitalize()} (MSE: {results[eq_type]["test_mse"]:.2f})')
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    ax.legend()
    ax.grid(True)

plt.tight_layout()
plt.savefig('polynomial_regression.png', dpi=150)
plt.show()

# ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржкрж░рзНржпржмрзЗржХрзНрж╖ржг (ржмрж╛ржВрж▓рж╛ржпрж╝)
print("\nЁЯУК ржкрж░рзНржпржмрзЗржХрзНрж╖ржг:")
print("1. ржпржд ржмрзЗрж╢рж┐ power (x┬│ > x┬▓ > x), рждржд ржмрзЗрж╢рж┐ hidden layers ржУ neurons ржкрзНрж░ржпрж╝рзЛржЬржи")
print("2. Cubic equation-ржПрж░ ржЬржирзНржп ржмрзЗрж╢рж┐ training data (2000 samples) ржкрзНрж░ржпрж╝рзЛржЬржи рж╣ржпрж╝рзЗржЫрзЗ")
print("3. Higher power = ржмрзЗрж╢рж┐ non-linearity = ржмрзЗрж╢рж┐ model complexity ржкрзНрж░ржпрж╝рзЛржЬржи")
print("4. EarlyStopping ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ overfitting ржХржорж╛ржирзЛ рж╣ржпрж╝рзЗржЫрзЗ")
```

### ЁЯУЭ рж░рж┐ржкрзЛрж░рзНржЯрзЗ ржпрж╛ рж▓рж┐ржЦржмрзЗржи:
- **Power vs Architecture:** Linear тЖТ 1 hidden layer, Quadratic тЖТ 2 layers, Cubic тЖТ 3 layers
- **Power vs Data Size:** Cubic ржПрж░ ржЬржирзНржп 2000 samples, Linear ржПрж░ ржЬржирзНржп 500 samples ржпржерзЗрж╖рзНржЯ
- **ржЧрзНрж░рж╛ржл:** Original vs Predicted ржкрзНрж▓ржЯ рж░рж┐ржкрзЛрж░рзНржЯрзЗ ржпрзЛржЧ ржХрж░рзБржи

---

## ЁЯСХ Assignment 4: FCFNN Classifier (Fashion MNIST, MNIST, CIFAR-10)

### ЁЯРН ржЗржЙржирж┐ржлрж╛ржЗржб ржХрзЛржб (рж╕ржм ржбрзЗржЯрж╛рж╕рзЗржЯрзЗрж░ ржЬржирзНржп)
```python
# assignment4_fcfnn_classifier.py
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

def train_fcfnn_on_dataset(dataset_name='mnist'):
    # ржбрзЗржЯрж╛рж╕рзЗржЯ рж▓рзЛржб ржХрж░рзБржи
    if dataset_name == 'mnist':
        (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
        input_shape = 784
        num_classes = 10
    elif dataset_name == 'fashion_mnist':
        (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()
        input_shape = 784
        num_classes = 10
    elif dataset_name == 'cifar10':
        (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
        x_train = x_train.reshape(-1, 3072)  # 32x32x3 = 3072
        x_test = x_test.reshape(-1, 3072)
        input_shape = 3072
        num_classes = 10
        y_train = y_train.flatten()
        y_test = y_test.flatten()
    
    # ржирж░ржорж╛рж▓рж╛ржЗржЬ ржХрж░рзБржи
    x_train = x_train.astype("float32") / 255.0
    x_test = x_test.astype("float32") / 255.0
    
    # ржоржбрзЗрж▓ рждрзИрж░рж┐ ржХрж░рзБржи (ржбрзЗржЯрж╛рж╕рзЗржЯ ржЕржирзБржпрж╛ржпрж╝рзА ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░ ржкрж░рж┐ржмрж░рзНрждржи)
    if dataset_name == 'cifar10':
        # CIFAR-10 complex, рждрж╛ржЗ ржмржбрж╝ ржоржбрзЗрж▓
        model = keras.Sequential([
            keras.layers.Dense(512, activation='relu', input_shape=(input_shape,)),
            keras.layers.Dropout(0.3),
            keras.layers.Dense(256, activation='relu'),
            keras.layers.Dropout(0.3),
            keras.layers.Dense(128, activation='relu'),
            keras.layers.Dense(num_classes, activation='softmax')
        ])
    else:
        # MNIST/Fashion-MNIST рж╕рж╣ржЬ
        model = keras.Sequential([
            keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),
            keras.layers.Dropout(0.2),
            keras.layers.Dense(64, activation='relu'),
            keras.layers.Dense(num_classes, activation='softmax')
        ])
    
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # ржЯрзНрж░рзЗржирж┐ржВ
    history = model.fit(
        x_train, y_train,
        batch_size=128,
        epochs=30,
        validation_split=0.1,
        callbacks=[
            keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),
            keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)
        ],
        verbose=1
    )
    
    # ржЯрзЗрж╕рзНржЯ рж╕рзЗржЯрзЗ ржорзВрж▓рзНржпрж╛ржпрж╝ржи
    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
    
    print(f"\nтЬЕ {dataset_name.upper()} рж░рзЗржЬрж╛рж▓рзНржЯ:")
    print(f"   ржЯрзЗрж╕рзНржЯ ржЕрзНржпрж╛ржХрзБрж░рзЗрж╕рж┐: {test_acc:.4f}")
    print(f"   ржЯрзЗрж╕рзНржЯ рж▓рж╕: {test_loss:.4f}")
    
    return history, test_acc, test_loss

# рж╕ржм ржбрзЗржЯрж╛рж╕рзЗржЯ ржЯрзЗрж╕рзНржЯ ржХрж░рзБржи
datasets = ['mnist', 'fashion_mnist', 'cifar10']
results = {}

for ds in datasets:
    history, acc, loss = train_fcfnn_on_dataset(ds)
    results[ds] = {'acc': acc, 'loss': loss, 'history': history}

# ржЕрзНржпрж╛ржХрзБрж░рзЗрж╕рж┐ ржХржорзНржкрзНржпрж╛рж░рж┐ржЬржи ржкрзНрж▓ржЯ
plt.figure(figsize=(8, 5))
plt.bar(results.keys(), [r['acc'] for r in results.values()], color=['blue', 'green', 'red'])
plt.ylabel('Test Accuracy')
plt.title('FCFNN Performance on Different Datasets')
plt.ylim(0, 1)
for i, (ds, r) in enumerate(results.items()):
    plt.text(i, r['acc'] + 0.02, f"{r['acc']:.2%}", ha='center')
plt.grid(axis='y', alpha=0.3)
plt.savefig('fcfnn_comparison.png', dpi=150)
plt.show()
```

### ЁЯУК ржкрзНрж░рждрзНржпрж╛рж╢рж┐ржд рж░рзЗржЬрж╛рж▓рзНржЯ:
| Dataset | Expected Accuracy |
|---------|-------------------|
| MNIST | 97-98% |
| Fashion MNIST | 88-90% |
| CIFAR-10 | 45-50% (FCFNN ржжрж┐ржпрж╝рзЗ) |

> ЁЯТб **ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг:** CIFAR-10-ржП FCFNN ржЦрж╛рж░рж╛ржк ржХрж░ржмрзЗ ржХрж╛рж░ржг ржПржЯрж┐ spatial information preserve ржХрж░рждрзЗ ржкрж╛рж░рзЗ ржирж╛ред ржПржЯрж╛ Assignment 5-ржП CNN ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ рж╕рж▓ржн ржХрж░рж╛ рж╣ржмрзЗред

---

## ЁЯФ╖ Assignment 5: CNN Classifier (Fashion MNIST, MNIST, CIFAR-10)

### ЁЯРН ржЗржЙржирж┐ржлрж╛ржЗржб CNN ржХрзЛржб
```python
# assignment5_cnn_classifier.py
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

def create_cnn_model(dataset_name='mnist'):
    if dataset_name == 'cifar10':
        # CIFAR-10 ржПрж░ ржЬржирзНржп deeper CNN
        model = keras.Sequential([
            layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(32,32,3)),
            layers.BatchNormalization(),
            layers.Conv2D(32, (3,3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2,2)),
            layers.Dropout(0.25),
            
            layers.Conv2D(64, (3,3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.Conv2D(64, (3,3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2,2)),
            layers.Dropout(0.25),
            
            layers.Flatten(),
            layers.Dense(512, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            layers.Dense(10, activation='softmax')
        ])
    else:
        # MNIST/Fashion-MNIST ржПрж░ ржЬржирзНржп simpler CNN
        model = keras.Sequential([
            layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
            layers.MaxPooling2D((2,2)),
            layers.Conv2D(64, (3,3), activation='relu'),
            layers.MaxPooling2D((2,2)),
            layers.Flatten(),
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(10, activation='softmax')
        ])
    
    model.compile(
        optimizer=keras.optimizers.Adam(0.001),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

def train_cnn_on_dataset(dataset_name='mnist'):
    # ржбрзЗржЯрж╛ рж▓рзЛржб ржУ ржкрзНрж░рж┐ржкрзНрж░рж╕рзЗрж╕
    if dataset_name == 'mnist':
        (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
        x_train = x_train.reshape(-1, 28, 28, 1)
        x_test = x_test.reshape(-1, 28, 28, 1)
    elif dataset_name == 'fashion_mnist':
        (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()
        x_train = x_train.reshape(-1, 28, 28, 1)
        x_test = x_test.reshape(-1, 28, 28, 1)
    elif dataset_name == 'cifar10':
        (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
        y_train = y_train.flatten()
        y_test = y_test.flatten()
    
    # ржирж░ржорж╛рж▓рж╛ржЗржЬ
    x_train = x_train.astype("float32") / 255.0
    x_test = x_test.astype("float32") / 255.0
    
    # ржоржбрзЗрж▓ рждрзИрж░рж┐
    model = create_cnn_model(dataset_name)
    model.summary()
    
    # ржЯрзНрж░рзЗржирж┐ржВ
    history = model.fit(
        x_train, y_train,
        batch_size=128,
        epochs=25,
        validation_split=0.1,
        callbacks=[
            keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),
            keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)
        ],
        verbose=1
    )
    
    # ржЯрзЗрж╕рзНржЯ ржорзВрж▓рзНржпрж╛ржпрж╝ржи
    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
    print(f"\nтЬЕ {dataset_name.upper()} CNN рж░рзЗржЬрж╛рж▓рзНржЯ: ржЕрзНржпрж╛ржХрзБрж░рзЗрж╕рж┐ = {test_acc:.4f}")
    
    return history, test_acc

# рж╕ржм ржбрзЗржЯрж╛рж╕рзЗржЯ ржЯрзЗрж╕рзНржЯ ржХрж░рзБржи
datasets = ['mnist', 'fashion_mnist', 'cifar10']
cnn_results = {}

for ds in datasets:
    history, acc = train_cnn_on_dataset(ds)
    cnn_results[ds] = {'acc': acc, 'history': history}
```

### ЁЯУК ржкрзНрж░рждрзНржпрж╛рж╢рж┐ржд рж░рзЗржЬрж╛рж▓рзНржЯ (CNN):
| Dataset | FCFNN Accuracy | CNN Accuracy | Improvement |
|---------|----------------|--------------|-------------|
| MNIST | ~98% | **~99.2%** | +1.2% |
| Fashion MNIST | ~90% | **~92-93%** | +2-3% |
| CIFAR-10 | ~48% | **~70-75%** | +22-27% |

> ЁЯТб **ржХрзА рж╢рж┐ржЦрж▓рж╛ржо:** CNN spatial features (edges, textures) extract ржХрж░рждрзЗ ржкрж╛рж░рзЗ, ржпрж╛ FCFNN ржкрж╛рж░рзЗ ржирж╛ред рждрж╛ржЗ CIFAR-10-ржП CNN ржЕржирзЗржХ ржнрж╛рж▓рзЛ ржХрж░рзЗред

---

## тЬНя╕П Assignment 6: Custom Handwritten Digit Dataset

### ЁЯУ▒ ржбрзЗржЯрж╛ ржХрж╛рж▓рзЗржХрж╢ржи рж╕рзНржЯрзЗржкрж╕:
1. ржЖржкржирж┐ ржУ ржЖржкржирж╛рж░ ржЧрзНрж░рзБржкржорзЗржЯрж░рж╛ рзж-рзп ржкрж░рзНржпржирзНржд digit ржХрж╛ржЧржЬрзЗ рж▓рж┐ржЦрзБржи
2. Mobile camera ржжрж┐ржпрж╝рзЗ ржЫржмрж┐ рждрзБрж▓рзБржи (рж╕рж╛ржжрж╛ ржмрзНржпрж╛ржХржЧрзНрж░рж╛ржЙржирзНржб, ржХрж╛рж▓рзЛ ржЗржирзНржХ)
3. ржкрзНрж░рждрж┐ржЯрж┐ digit-ржПрж░ ржЬржирзНржп ржЕржирзНрждржд рзирзжржЯрж┐ ржЫржмрж┐ рждрзБрж▓рзБржи (ржорзЛржЯ рзирзжрзж+ ржЫржмрж┐)
4. ржлрзЛрж▓рзНржбрж╛рж░ рж╕рзНржЯрзНрж░рж╛ржХржЪрж╛рж░:
```
custom_digits/
тФЬтФАтФА 0/
тФЬтФАтФА 1/
тФЬтФАтФА ...
тФФтФАтФА 9/
```

### ЁЯРН ржЯрзНрж░рзЗржирж┐ржВ ржХрзЛржб (MNIST + Custom Data)
```python
# assignment6_custom_digits.py
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import os
from PIL import Image
import matplotlib.pyplot as plt

# Step 1: Custom data load ржХрж░рзБржи
def load_custom_digits(data_dir, img_size=(28,28)):
    images, labels = [], []
    for label in range(10):
        folder = os.path.join(data_dir, str(label))
        if not os.path.exists(folder):
            continue
        for fname in os.listdir(folder):
            if fname.endswith(('.png', '.jpg', '.jpeg')):
                img = Image.open(os.path.join(folder, fname)).convert('L')  # Grayscale
                img = img.resize(img_size)
                img = np.array(img).astype('float32') / 255.0
                images.append(img)
                labels.append(label)
    return np.array(images), np.array(labels)

# Step 2: MNIST data load ржХрж░рзБржи
(x_mnist, y_mnist), (x_test, y_test) = keras.datasets.mnist.load_data()
x_mnist = x_mnist.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Step 3: Custom data load ржХрж░рзБржи (ржЖржкржирж╛рж░ ржбрж┐рж░рзЗржХрзНржЯрж░рж┐ ржкрж╛рже ржжрж┐ржи)
custom_dir = '/content/custom_digits'  # Colab-ржП mount ржХрж░рзБржи
x_custom, y_custom = load_custom_digits(custom_dir)

# Step 4: Data combine ржХрж░рзБржи
x_train = np.concatenate([x_mnist, x_custom], axis=0)
y_train = np.concatenate([y_mnist, y_custom], axis=0)

# Reshape for CNN
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# Step 5: CNN ржоржбрзЗрж▓
model = keras.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Step 6: ржЯрзНрж░рзЗржирж┐ржВ
history = model.fit(
    x_train, y_train,
    epochs=15,
    batch_size=128,
    validation_split=0.1,
    callbacks=[keras.callbacks.EarlyStopping(patience=3)]
)

# Step 7: ржорзВрж▓рзНржпрж╛ржпрж╝ржи
# (a) MNIST test set
mnist_loss, mnist_acc = model.evaluate(x_test, y_test, verbose=0)
print(f"MNIST Test Accuracy: {mnist_acc:.4f}")

# (b) Custom test set (custom data ржерзЗржХрзЗ 20% test рж╣рж┐рж╕рзЗржмрзЗ рж░рж╛ржЦрзБржи)
split = int(0.8 * len(x_custom))
x_custom_test = x_custom[split:].reshape(-1, 28, 28, 1)
y_custom_test = y_custom[split:]
custom_loss, custom_acc = model.evaluate(x_custom_test, y_custom_test, verbose=0)
print(f"Custom Data Test Accuracy: {custom_acc:.4f}")
```

---

## ЁЯУ╕ Assignment 7: Mobile-Captured Image Classification

### ЁЯУ▒ ржбрзЗржЯрж╛ ржХрж╛рж▓рзЗржХрж╢ржи ржЧрж╛ржЗржбрж▓рж╛ржЗржи:
1. рзл-рззрзж ржЬржи ржЧрзНрж░рзБржкржорзЗржЯ ржирж┐ржи
2. ржкрзНрж░рждрзНржпрзЗржХрзЗрж░ рзлрзжржЯрж┐ ржЫржмрж┐ mobile camera ржжрж┐ржпрж╝рзЗ рждрзБрж▓рзБржи (ржлрзЗрж╕ ржмрж╛ ржЕржмржЬрзЗржХрзНржЯ)
3. рж▓рзЗржмрзЗрж▓: person1, person2, ..., personN
4. Total data: 250-500 images

### ЁЯРН ржЯрзНрж░рзЗржирж┐ржВ ржХрзЛржб + ржорзЗржЯрзНрж░рж┐ржХрзНрж╕ ржЯрзНрж░рзНржпрж╛ржХрж┐ржВ
```python
# assignment7_mobile_images.py
import time
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np

# Data augmentation
datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

# Data loading (Colab-ржП Google Drive mount ржХрж░рзБржи)
train_generator = datagen.flow_from_directory(
    '/content/mobile_images',
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

val_generator = datagen.flow_from_directory(
    '/content/mobile_images',
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# CNN Model
model = keras.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(train_generator.num_classes, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Training with timing
start_time = time.time()
history = model.fit(
    train_generator,
    epochs=25,
    validation_data=val_generator,
    callbacks=[keras.callbacks.EarlyStopping(patience=5)]
)
total_training_time = time.time() - start_time

# Testing time per sample
test_batch = val_generator.next()
start_test = time.time()
preds = model.predict(test_batch[0], verbose=0)
test_time = (time.time() - start_test) / len(test_batch[0])

# Results
print(f"\nтЬЕ ржЯрзНрж░рзЗржирж┐ржВ рж╕ржоржпрж╝: {total_training_time:.2f} рж╕рзЗржХрзЗржирзНржб")
print(f"тЬЕ ржЯрзЗрж╕рзНржЯрж┐ржВ рж╕ржоржпрж╝ ржкрзНрж░рждрж┐ рж╕рзНржпрж╛ржорзНржкрж▓: {test_time*1000:.2f} ms")
print(f"тЬЕ ржорзЛржЯ ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░: {model.count_params():,}")
print(f"тЬЕ ржнрзНржпрж╛рж▓рж┐ржбрзЗрж╢ржи ржЕрзНржпрж╛ржХрзБрж░рзЗрж╕рж┐: {max(history.history['val_accuracy']):.4f}")

# Performance curves
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Val')
plt.title('Accuracy vs Epoch')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Val')
plt.title('Loss vs Epoch')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.savefig('mobile_images_performance.png', dpi=150)
plt.show()
```

### ЁЯУК рж░рж┐ржкрзЛрж░рзНржЯрзЗ ржпрзЛржЧ ржХрж░рзБржи:
- ржбрзЗржЯрж╛ vs ржЕрзНржпрж╛ржХрзБрж░рзЗрж╕рж┐ ржЯрзЗржмрж┐рж▓ (50, 100, 200, 500 images)
- Epoch vs Accuracy ржЧрзНрж░рж╛ржл
- Model size (parameters) vs Performance
- Training time vs Data size

---

## ЁЯза Assignment 8: VGG16-like Architecture

### ЁЯРН VGG16 Implementation (without pretraining)
```python
# assignment8_vgg16.py
from tensorflow import keras
from tensorflow.keras import layers

def create_vgg16_like(input_shape=(224,224,3), num_classes=10):
    model = keras.Sequential(name='VGG16_Like')
    
    # Block 1
    model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same', input_shape=input_shape))
    model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))
    
    # Block 2
    model.add(layers.Conv2D(128, (3,3), activation='relu', padding='same'))
    model.add(layers.Conv2D(128, (3,3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))
    
    # Block 3
    model.add(layers.Conv2D(256, (3,3), activation='relu', padding='same'))
    model.add(layers.Conv2D(256, (3,3), activation='relu', padding='same'))
    model.add(layers.Conv2D(256, (3,3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))
    
    # Block 4
    model.add(layers.Conv2D(512, (3,3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3,3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3,3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))
    
    # Block 5
    model.add(layers.Conv2D(512, (3,3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3,3), activation='relu', padding='same'))
    model.add(layers.Conv2D(512, (3,3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D((2,2), strides=(2,2)))
    
    # Classification block
    model.add(layers.Flatten())
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(4096, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(num_classes, activation='softmax'))
    
    return model

# ржоржбрзЗрж▓ рждрзИрж░рж┐ ржУ рж╕рж╛рж░рж╕ржВржХрзНрж╖рзЗржк
model = create_vgg16_like(input_shape=(32,32,3), num_classes=10)  # CIFAR-10 ржПрж░ ржЬржирзНржп
model.summary()

# ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░ ржЧржгржирж╛
print(f"\nржорзЛржЯ ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░: {model.count_params():,}")
```

> ЁЯТб **ржирзЛржЯ:** Original VGG16 224x224 input ржирзЗржпрж╝, ржХрж┐ржирзНрждрзБ CIFAR-10 ржПрж░ ржЬржирзНржп ржЖржорж░рж╛ 32x32 input ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗржЫрж┐ред ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░ ржПржХржЗ рж░рзЗржЦрзЗржЫрж┐ред

---

## ЁЯФН Assignment 9: Feature Map Visualization

### ЁЯРН Pre-trained CNN Feature Map Visualization
```python
# assignment9_feature_maps.py
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess

# ржЗржорзЗржЬ рж▓рзЛржб ржХрж░рзБржи (ржЖржкржирж╛рж░ ржкржЫржирзНржжрзЗрж░ ржЗржорзЗржЬ)
img_path = '/content/your_image.jpg'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)

# рждрж┐ржиржЯрж┐ pre-trained ржоржбрзЗрж▓ рж▓рзЛржб ржХрж░рзБржи
models = {
    'VGG16': (VGG16(weights='imagenet', include_top=False), vgg_preprocess(x)),
    'ResNet50': (ResNet50(weights='imagenet', include_top=False), resnet_preprocess(x)),
    'MobileNetV2': (MobileNetV2(weights='imagenet', include_top=False), mobilenet_preprocess(x))
}

# Feature map visualize ржХрж░рзБржи
for name, (model, preprocessed_img) in models.items():
    print(f"\n{name} ржПрж░ feature maps...")
    
    # ржкрзНрж░ржержо convolutional layer ржерзЗржХрзЗ feature maps ржкрж╛ржи
    layer_outputs = [layer.output for layer in model.layers[:5]]  # ржкрзНрж░ржержо рзл рж▓рзЗржпрж╝рж╛рж░
    activation_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)
    
    activations = activation_model.predict(preprocessed_img)
    
    # ржкрзНрж░ржержо layer-ржПрж░ feature maps ржкрзНрж▓ржЯ ржХрж░рзБржи
    first_layer_activation = activations[0]
    n_features = min(8, first_layer_activation.shape[-1])  # ржкрзНрж░ржержо рзоржЯрж┐ filter
    
    plt.figure(figsize=(15, 4))
    for i in range(n_features):
        plt.subplot(1, n_features, i+1)
        plt.imshow(first_layer_activation[0, :, :, i], cmap='viridis')
        plt.axis('off')
    plt.suptitle(f'{name} - Layer 1 Feature Maps', fontsize=16)
    plt.savefig(f'{name}_feature_maps.png', dpi=150, bbox_inches='tight')
    plt.show()
```

### ЁЯУЭ рж░рж┐ржкрзЛрж░рзНржЯрзЗ рж▓рж┐ржЦрзБржи:
- VGG16: Low-level features (edges, corners)
- ResNet50: Edge + texture features (skip connections ржПрж░ ржХрж╛рж░ржгрзЗ ржнрж╛рж▓рзЛ)
- MobileNetV2: Efficient but slightly less detailed features

---

## тЪЩя╕П Assignment 10: Transfer Learning with VGG16

### ЁЯРН Full vs Partial Fine-tuning
```python
# assignment10_transfer_learning.py
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# ржбрзЗржЯрж╛ ржкрзНрж░рж┐ржкрзНрж░рж╕рзЗрж╕рж┐ржВ
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
x_train = tf.image.resize(x_train, (160, 160))  # VGG16 ржПрж░ ржЬржирзНржп minimum 32x32, ржХрж┐ржирзНрждрзБ 160x160 ржнрж╛рж▓рзЛ
x_test = tf.image.resize(x_test, (160, 160))
x_train = tf.cast(x_train, tf.float32) / 255.0
x_test = tf.cast(x_test, tf.float32) / 255.0
y_train = y_train.flatten()
y_test = y_test.flatten()

def create_model(fine_tune_all=False):
    # Base model (pre-trained)
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(160,160,3))
    
    if not fine_tune_all:
        # Partial fine-tuning: рж╢рзБржзрзБ top layers ржЯрзНрж░рзЗржЗржи ржХрж░ржм
        base_model.trainable = False
    else:
        # Full fine-tuning: рж╕ржм layers ржЯрзНрж░рзЗржЗржи ржХрж░ржм
        base_model.trainable = True
        # рж╢рзБржзрзБ last 5 layers unfreeze ржХрж░рзБржи (optional)
        for layer in base_model.layers[:-5]:
            layer.trainable = False
    
    # Classification head
    model = keras.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(10, activation='softmax')
    ])
    
    model.compile(
        optimizer=keras.optimizers.Adam(1e-4 if fine_tune_all else 1e-3),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# Experiment 1: Partial fine-tuning
print("ЁЯФД Partial Fine-tuning (Feature Extraction)...")
model_partial = create_model(fine_tune_all=False)
history_partial = model_partial.fit(
    x_train, y_train,
    epochs=10,
    batch_size=64,
    validation_split=0.1,
    verbose=1
)

# Experiment 2: Full fine-tuning
print("\nЁЯФД Full Fine-tuning...")
model_full = create_model(fine_tune_all=True)
history_full = model_full.fit(
    x_train, y_train,
    epochs=10,
    batch_size=64,
    validation_split=0.1,
    verbose=1
)

# рж░рзЗржЬрж╛рж▓рзНржЯ ржХржорзНржкрзЗржпрж╝рж╛рж░
partial_acc = max(history_partial.history['val_accuracy'])
full_acc = max(history_full.history['val_accuracy'])

print(f"\nтЬЕ Partial Fine-tuning Val Accuracy: {partial_acc:.4f}")
print(f"тЬЕ Full Fine-tuning Val Accuracy: {full_acc:.4f}")
print(f"тЬЕ Improvement: {(full_acc - partial_acc)*100:.2f}%")

# ржкрзНрж▓ржЯ
plt.figure(figsize=(10,4))
plt.plot(history_partial.history['val_accuracy'], label='Partial FT')
plt.plot(history_full.history['val_accuracy'], label='Full FT')
plt.title('Partial vs Full Fine-tuning')
plt.xlabel('Epoch')
plt.ylabel('Validation Accuracy')
plt.legend()
plt.grid(True)
plt.savefig('fine_tuning_comparison.png', dpi=150)
plt.show()
```

### ЁЯУК ржкрзНрж░рждрзНржпрж╛рж╢рж┐ржд рж░рзЗржЬрж╛рж▓рзНржЯ:
- Partial FT: ~75-80% accuracy (рж╢рзБржзрзБ classifier head ржЯрзНрж░рзЗржЗржи)
- Full FT: ~82-87% accuracy (рж╕ржм layers ржЯрзБржЗржХ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ)
- рж╕ржоржпрж╝: Full FT ржмрзЗрж╢рж┐ рж╕ржоржпрж╝ ржирзЗржпрж╝ ржХрж┐ржирзНрждрзБ ржнрж╛рж▓рзЛ рж░рзЗржЬрж╛рж▓рзНржЯ ржжрзЗржпрж╝

---

## ЁЯУЙ Assignment 11: PCA/t-SNE Visualization of Features

### ЁЯРН Feature Extraction + Dimensionality Reduction
```python
# assignment11_pca_tsne.py
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import VGG16
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import numpy as np

# ржбрзЗржЯрж╛ рж▓рзЛржб
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train = x_train[:1000]  # ржжрзНрж░рзБржд ржкрзНрж░рж╕рзЗрж╕рж┐ржВржпрж╝рзЗрж░ ржЬржирзНржп рззрзжрзжрзж рж╕рзНржпрж╛ржорзНржкрж▓
y_train = y_train[:1000]
x_train = np.stack([x_train]*3, axis=-1)  # Grayscale тЖТ RGB (VGG16 ржПрж░ ржЬржирзНржп)
x_train = tf.image.resize(x_train, (32,32))  # VGG16 minimum size
x_train = tf.cast(x_train, tf.float32) / 255.0

# Pre-trained VGG16 (ImageNet)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32,32,3))
feature_extractor = keras.Model(
    inputs=base_model.input,
    outputs=base_model.get_layer('block4_pool').output  # Intermediate layer
)

# Features extract ржХрж░рзБржи
features = feature_extractor.predict(x_train, verbose=0)
features_flat = features.reshape(features.shape[0], -1)

# PCA (2D)
pca = PCA(n_components=2)
features_pca = pca.fit_transform(features_flat)

# t-SNE (2D)
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
features_tsne = tsne.fit_transform(features_flat[:500])  # t-SNE slow, so 500 samples

# ржкрзНрж▓ржЯ
plt.figure(figsize=(12,5))

# PCA Plot
plt.subplot(1,2,1)
scatter = plt.scatter(features_pca[:,0], features_pca[:,1], c=y_train, cmap='tab10', alpha=0.6)
plt.colorbar(scatter)
plt.title('PCA of VGG16 Features (Before Transfer Learning)')

# t-SNE Plot
plt.subplot(1,2,2)
scatter = plt.scatter(features_tsne[:,0], features_tsne[:,1], c=y_train[:500], cmap='tab10', alpha=0.6)
plt.colorbar(scatter)
plt.title('t-SNE of VGG16 Features')

plt.tight_layout()
plt.savefig('feature_visualization.png', dpi=150)
plt.show()

print(f"тЬЕ PCA explained variance ratio: {pca.explained_variance_ratio_}")
```

### ЁЯУЭ рж░рж┐ржкрзЛрж░рзНржЯрзЗ рж▓рж┐ржЦрзБржи:
- PCA: Global structure preserve ржХрж░рзЗ, ржХрж┐ржирзНрждрзБ non-linear relationships ржжрзЗржЦрж╛ржпрж╝ ржирж╛
- t-SNE: Local clusters ржнрж╛рж▓рзЛ ржжрзЗржЦрж╛ржпрж╝, ржХрж┐ржирзНрждрзБ global structure distort ржХрж░рзЗ
- Transfer learning ржПрж░ ржкрж░рзЗ features ржЖрж░ржУ рж╕рзНржкрж╖рзНржЯржнрж╛ржмрзЗ cluster рж╣ржмрзЗ

---

## ЁЯФД Assignment 12-16: Callbacks, Augmentation, Overfitting, Activation Functions

### ЁЯУж рж╕ржмржЧрзБрж▓рзЛрж░ ржЬржирзНржп ржЗржЙржирж┐ржлрж╛ржЗржб ржХрзЛржб (Colab Notebook рж╣рж┐рж╕рзЗржмрзЗ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи)

```python
# assignments_12_to_16.py
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import numpy as np

# ржбрзЗржЯрж╛ рж▓рзЛржб
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
y_train = y_train.flatten()
y_test = y_test.flatten()

# ========== Assignment 12: Data Augmentation ==========
datagen_none = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
datagen_basic = keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1
)
datagen_advanced = keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# ========== Assignment 13: Dropout for Overfitting ==========
def create_model(dropout_rate=0.0, augmentation=None):
    model = keras.Sequential([
        layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(32,32,3)),
        layers.Conv2D(32, (3,3), activation='relu', padding='same'),
        layers.MaxPooling2D((2,2)),
        layers.Dropout(dropout_rate),
        
        layers.Conv2D(64, (3,3), activation='relu', padding='same'),
        layers.Conv2D(64, (3,3), activation='relu', padding='same'),
        layers.MaxPooling2D((2,2)),
        layers.Dropout(dropout_rate),
        
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(dropout_rate),
        layers.Dense(10, activation='softmax')
    ])
    
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# Dropout ржПржХрзНрж╕ржкрзЗрж░рж┐ржорзЗржирзНржЯ
models_dropout = {}
for dr in [0.0, 0.3, 0.5]:
    print(f"\nTraining with dropout={dr}")
    model = create_model(dropout_rate=dr)
    history = model.fit(
        x_train, y_train,
        epochs=25,
        batch_size=64,
        validation_split=0.1,
        verbose=0,
        callbacks=[keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)]
    )
    models_dropout[dr] = history

# ржкрзНрж▓ржЯ: Dropout vs Overfitting
plt.figure(figsize=(12,4))
for idx, (dr, hist) in enumerate(models_dropout.items()):
    plt.subplot(1,3,idx+1)
    plt.plot(hist.history['accuracy'], label='Train')
    plt.plot(hist.history['val_accuracy'], label='Val')
    plt.title(f'Dropout={dr}')
    plt.ylim(0,1)
    plt.legend()
plt.tight_layout()
plt.savefig('dropout_overfitting.png', dpi=150)
plt.show()

# ========== Assignment 14: Activation Functions ==========
activations = ['relu', 'tanh', 'sigmoid']
results_activation = {}

for act in activations:
    print(f"\nTraining with activation={act}")
    model = keras.Sequential([
        layers.Conv2D(32, (3,3), activation=act, padding='same', input_shape=(32,32,3)),
        layers.MaxPooling2D((2,2)),
        layers.Conv2D(64, (3,3), activation=act, padding='same'),
        layers.MaxPooling2D((2,2)),
        layers.Flatten(),
        layers.Dense(128, activation=act),
        layers.Dense(10, activation='softmax')
    ])
    
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    history = model.fit(x_train, y_train, epochs=15, batch_size=64, validation_split=0.1, verbose=0)
    results_activation[act] = max(history.history['val_accuracy'])

print("\nтЬЕ Activation Function Comparison:")
for act, acc in results_activation.items():
    print(f"   {act:10s}: {acc:.4f}")

# ========== Assignment 15: Callbacks ==========
callbacks = [
    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, verbose=1),
    keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, verbose=1),
    keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True, verbose=1),
    keras.callbacks.TensorBoard(log_dir='./logs')  # TensorBoard visualization
]

# ========== Assignment 16: Performance Curves ==========
model = create_model(dropout_rate=0.3)
history = model.fit(
    x_train, y_train,
    epochs=30,
    batch_size=64,
    validation_split=0.1,
    callbacks=callbacks,
    verbose=1
)

# ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржХрж╛рж░рзНржн ржкрзНрж▓ржЯ
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.axhline(y=0.9, color='r', linestyle='--', label='Target 90%')
plt.title('Accuracy Curves')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss Curves')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.savefig('performance_curves.png', dpi=150)
plt.show()

# рж╣рж╛ржЗржкрж╛рж░ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░ ржЯрж┐ржЙржирж┐ржВ ржЧрж╛ржЗржбрж▓рж╛ржЗржи
print("\nЁЯУК рж╣рж╛ржЗржкрж╛рж░ржкрзНржпрж╛рж░рж╛ржорж┐ржЯрж╛рж░ ржЯрж┐ржЙржирж┐ржВ ржЧрж╛ржЗржб:")
print("1. ржпржжрж┐ training accuracy тЖС ржХрж┐ржирзНрждрзБ validation accuracy тЖУ тЖТ Overfitting (Dropout/Regularization ржмрж╛ржбрж╝рж╛ржи)")
print("2. ржпржжрж┐ ржжрзБржЗржЯрж╛ржЗ ржХржо тЖТ Underfitting (Model complexity ржмрж╛ржбрж╝рж╛ржи ржЕржержмрж╛ ржЯрзНрж░рзЗржирж┐ржВ рж╕ржоржпрж╝ ржмрж╛ржбрж╝рж╛ржи)")
print("3. ржпржжрж┐ loss ржЕрж╕рзНржерж┐рж░ тЖТ Learning rate ржХржорж╛ржи")
print("4. Validation loss ржмрж╛ржбрж╝рж▓рзЗ EarlyStopping ржХрж╛ржЬ ржХрж░ржмрзЗ")
```

---

## ЁЯУЪ рж╕рж╛рж░рж╕ржВржХрзНрж╖рзЗржк: рж╕ржм Assignment-ржПрж░ ржЬржирзНржп LaTeX Template

Overleaf-ржП ржирж┐ржЪрзЗрж░ template ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи:

```latex
\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

\title{AI Lab Assignments Report \\ University of Rajshahi \\ Faculty of Engineering \\ Department of CSE}
\author{Your Name \\ ID: XXXXXXXX}
\date{\today}

\begin{document}
\maketitle

\section{Assignment 1: FCFNN Drawing}
\begin{itemize}
    \item Input: 8 neurons
    \item Hidden 1: 4 neurons
    \item Hidden 2: 8 neurons
    \item Hidden 3: 4 neurons
    \item Output: 10 neurons
\end{itemize}
Figure \ref{fig:fcfnn} shows the manually drawn network.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{fcfnn_drawing.jpg}
    \caption{Manually drawn FCFNN}
    \label{fig:fcfnn}
\end{figure}

% ... continue for all assignments ...

\section{Conclusion}
We successfully implemented various neural network architectures including FCFNN, CNN, and transfer learning models. Key findings:
\begin{itemize}
    \item CNN outperforms FCFNN significantly on image data (especially CIFAR-10)
    \item Transfer learning with VGG16 achieves high accuracy with less data
    \item Data augmentation and dropout effectively reduce overfitting
    \item Higher polynomial degree requires deeper networks and more data
\end{itemize}

\end{document}
```

---

## тЬЕ ржкрж░ржмрж░рзНрждрзА ржкржжржХрзНрж╖рзЗржк:

1. **ржкрзНрж░рждрж┐ржЯрж┐ assignment ржЖрж▓рж╛ржжрж╛ Colab notebook ржП ржХрж░рзБржи**
2. **Overleaf-ржП LaTeX report рждрзИрж░рж┐ ржХрж░рзБржи**
3. **Assignment 6 ржУ 7 ржПрж░ ржЬржирзНржп ржирж┐ржЬрзЗрж░ ржбрзЗржЯрж╛ ржХрж╛рж▓рзЗржХрзНржЯ ржХрж░рзБржи**
4. **рж╕ржм ржЧрзНрж░рж╛ржл ржУ рж░рзЗржЬрж╛рж▓рзНржЯ report-ржП ржпрзЛржЧ ржХрж░рзБржи**
5. **ржкрзНрж░рждрж┐ржЯрж┐ assignment ржПрж░ ржЬржирзНржп рзи-рзй ржкрзГрж╖рзНржарж╛рж░ рж░рж┐ржкрзЛрж░рзНржЯ рж▓рж┐ржЦрзБржи**

> ЁЯУМ **рж╕рждрж░рзНржХрждрж╛:** ржПржЗ ржХрзЛржбржЧрзБрж▓рзЛ educational purpose ржП ржжрзЗржУржпрж╝рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржирж┐ржЬрзЗ ржХрж░рзЗ ржмрзБржЭрзЗ ржирж┐ржи, рж╢рзБржзрзБ copy-paste ржХрж░ржмрзЗржи ржирж╛ред ржкрзНрж░рждрж┐ржЯрж┐ рж▓рж╛ржЗржи ржмрзБржЭрзЗ ржирж┐ржи ржХрзЗржи ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред

рж╕ржм assignment complete ржХрж░рждрзЗ рж╕рж╛рж╣рж╛ржпрзНржп рж▓рж╛ржЧрж▓рзЗ ржЖржмрж╛рж░ ржЬрж┐ржЬрзНржЮрж╛рж╕рж╛ ржХрж░рзБржи! ЁЯШК
